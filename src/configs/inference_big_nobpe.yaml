defaults:
  - model: ds2_31Dec
  - metrics: ds2_all
  - datasets: full_ds_test_check # full_ds_test # full_ds_test_check # full_ds_test # we do not want to run inference on training data
  - dataloader: server_small # server # server_small # server2
  - transforms: transforms # to check
  - _self_
inferencer:
  # device_tensors: ["data_object", "labels"] # which tensors should be on device (ex. GPU)
  device_tensors: ["spectrogram", "text_encoded"]
  device: auto # device name or "auto"
  save_path: "saved_nobpe_03Jan/inference"  # any name here, can be a dataset name
  seed: 1
  from_pretrained: "saved_nobpe_03Jan/ds2_lm/model_best.pth" # path to the pretrained model
  # lm_weight: 0.5 # less for lighter model
  beam_size: 100 # New input
text_encoder:
  _target_: src.text_encoder.CTCTextEncoder
  arpa_path: 4-gram_lc_correct.arpa
  binary_path: 4-gram_lc_correct.bin
  # arpa_path: ~
  # binary_path: ~
  lm_weight: 0.7 # 0.5
  unigram_path: librispeech-vocab.txt
  # unigram_path: ~
  use_bpe: False
  pretrained_tokenizer: "sentencepiece_model/librispeech_unigram_model1000_new2.model"
  use_lm: True
  use_beam_search: True
  
  
